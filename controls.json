{
    "SecureInfrastructure" : {
      "overview" : "Secure Infrastructure refers to the establishment of robust and resilient systems that safeguard digital assets and data against unauthorised access, breaches, and cyber threats. It involves implementing a combination of hardware, software, policies, and procedures designed to protect networks, servers, applications, and other critical components from vulnerabilities and attacks. By prioritizing security measures such as encryption, access controls, and regular audits, organizations can mitigate risks and ensure the integrity and confidentiality of their infrastructure.",
      "qnum" : "1",
      "title" : "Secure Infrastructure",
      "1": "Config Management",
      "1-summary": "Configuration management is the systematic process of managing and controlling changes to a systems configuration ensuring consistently, reliability and traceability throughout its lifecycle",
      "1-tier": "Foundation",
      "1-points": "1",
      "1-conversation" : "",
      "1-recommendation" : "Establish a centralised repository for all configuration items and implement automated tools for version control, ensuring consistency and traceability across the system. Additionally, regularly review and update configuration baselines to reflect changes accurately, maintaining alignment with organizational objectives and standards",
      "2": "Segmentation / Isolation",
      "2-summary": "Infrastructure segmentation is the practice of dividing a network's resources and services into separate segments or zones to enhance security, improve performance, and facilitate easier management. This approach helps isolate critical assets, limit the spread of potential security breaches, and ensure that only authorised users have access to sensitive information. By implementing infrastructure segmentation, organizations can effectively enforce security policies, reduce the risk of unauthorised access, and support compliance efforts, all while maintaining operational efficiency across their IT environments.",
      "2-tier": "Foundation",
      "2-points": "2",
      "2-conversation" : "",
      "2-recommendation" : "Start by clearly defining your network's critical assets and sensitive data. Develop a segmentation strategy based on these assets, implementing network segmentation controls like firewalls, VLANs, and access controls. Regularly review and update your segmentation strategy to adapt to evolving threats and changes in your network infrastructure.",
      "3": "Logging & Monitoring",
      "3-summary": "Logging and monitoring encompass the collection and analysis of system and application logs to identify, diagnose, and respond to potential issues, ensuring operational health and security. Logging and monitoring aid in detecting anomalies, optimizing performance, and maintaining compliance within IT environments.",
      "3-tier": "Foundation",
      "3-points": "3",
      "3-conversation" : "",
      "3-recommendation" : "Identify key assets, systems, and potential threats. Implement centralised logging to collect and analyze data from across your infrastructure. Set up real-time monitoring to detect and respond to security incidents promptly. Regularly review and analyze logs to identify trends, anomalies, and potential security risks.",
      "4": "Automated Policy / Enforcement",
      "4-summary": "Automated policy enforcement enables the continuous application and compliance verification of defined security policies across an IT environment, ensuring configurations and operations adhere to established standards. This mechanism streamlines security management, reduces human error, and ensures a consistent security posture through automation.",
      "4-tier": "Strategic",
      "4-points": "4",
      "4-conversation" : "",
      "4-recommendation" : "Start by clearly defining your security policies and compliance requirements. Implement automated tools and solutions to enforce these policies consistently across your infrastructure. Regularly review and update your policies to adapt to evolving threats and changes in your infrastructure. Test and validate automated policy enforcement regularly to ensure effectiveness and compliance.",
      "5": "Secrets Management",
      "5-summary": "Secrets management involves the secure handling, storage, and access control of sensitive information such as passwords, keys, and tokens to prevent unauthorised access and breaches. It ensures that secrets are encrypted, access is strictly controlled, and usage is audited, bolstering an organization's security framework.",
      "5-tier": "Strategic",
      "5-points": "5",
      "5-conversation" : "",
      "5-recommendation" : "Review and analyse what a Secret is for your company (SSH-Keys, API Credentials, Passwords, Privatekeys, PubKeys) and on which systems they occur (Windows, Linux, Server, Client, Cloud). Decide on your secret strategy (i.e. short lived vs. long lived secrets; Revocation or not). Discover and implement a solution, which covers your needs across the secret lifecycle (Creation, Rotation, Revocation) and your systems (Linux, Windows, Clients).",
      "6": "Container Runtime Security",
      "6-summary": "Container runtime security focuses on protecting containers during their execution by monitoring and enforcing security policies to prevent unauthorised activities and vulnerabilities. It involves isolating containers, scanning for threats in real-time, and ensuring compliance with security standards to safeguard applications and data.",
      "6-tier": "Strategic",
      "6-points": "6",
      "6-conversation" : "",
      "6-recommendation" : "Start by implementing image scanning to detect vulnerabilities before deployment. Utilise runtime protection tools to monitor container activity and detect malicious behavior. Implement least privilege principles and regular updates to minimise security risks. Finally, ensure continuous monitoring and periodic security assessments to maintain a robust security posture.",
      "7": "Service Mesh Security",
      "7-summary": "Service mesh security enhances the security of microservices architectures by managing, encrypting, and controlling inter-service communication through consistent, policy-driven access controls and authentication. This approach ensures that data in transit is protected and only authorised services can communicate, thereby reducing the attack surface within distributed applications.",
      "7-tier": "Advanced",
      "7-points": "7",
      "7-conversation" : "",
      "7-recommendation" : "Start by establishing strong identity and access management controls for services. Utilise mutual TLS encryption to secure communication between services within the mesh. Implement access control policies to enforce least privilege access. Regularly audit and monitor service mesh traffic for anomalies and potential security threats.",
      "8": "Identity-Based Perimeter",
      "8-summary": "Identity-based perimeter security focuses on establishing access controls and security measures based on the identity and credentials of users and devices, rather than traditional network boundaries. This model ensures that only authenticated and authorised entities can access resources, enhancing security in increasingly distributed and mobile environments.",
      "8-tier": "Advanced",
      "8-points": "8",
      "8-conversation" : "",
      "8-recommendation" : "Start by establishing strong authentication mechanisms such as multi-factor authentication (MFA) and single sign-on (SSO). Utilise identity and access management (IAM) solutions to enforce granular access controls based on user identities. Implement continuous monitoring and behavior analytics to detect and respond to suspicious activities. Regularly review and update access policies to adapt to evolving security threats and changes in your infrastructure."
      },
    "SecureData" : {
      "overview" : "Secure Data encompasses strategies and technologies aimed at protecting sensitive information from unauthorised access, modification, or disclosure. This involves employing encryption, access controls, and data masking techniques to safeguard data both in transit and at rest. By implementing robust security measures and adhering to compliance standards, organizations can mitigate the risks of data breaches and uphold the confidentiality, integrity, and availability of their data assets.",
      "qnum" : "2",
      "title" : "Secure Data",
      "1": "Classification",
      "1-summary": "Data classification involves categorizing organizational data based on sensitivity and relevance, enabling tailored protection measures and compliance with regulatory requirements. This process helps prioritise data security efforts, ensuring that higher sensitivity data receives more stringent protections to mitigate the risk of breaches and unauthorised access.",
      "1-tier": "Foundation",
      "1-points": "1",
      "1-conversation" : "",
      "1-recommendation" : "Start by identifying and categorizing your data based on sensitivity and importance. Develop clear classification criteria and labels. Utilise automated tools to classify and tag data based on these criteria. Implement access controls and encryption based on data classification.",
      "2": "Encryption",
      "2-summary": "Encryption transforms readable data into a coded format that can only be accessed or decrypted by authorised parties with the correct key, providing a critical layer of security for protecting sensitive information from unauthorised access and breaches. This technique is essential for safeguarding data at rest, in transit, and during processing across various digital platforms and communications.",
      "2-tier": "Foundation",
      "2-points": "2",
      "2-conversation" : "",
      "2-recommendation" : "Start by identifying sensitive data across your infrastructure. Utilise strong encryption algorithms to protect data both at rest and in transit. Implement encryption key management practices to securely generate, store, and rotate encryption keys.",
      "3": "Access Control",
      "3-summary": "Data access control is the process of restricting access to data by defining who is authorised to view or use specific data resources, based on roles, responsibilities, or attributes. It is a fundamental security measure that helps prevent unauthorised access and data breaches, ensuring that sensitive information is only accessible to vetted individuals or systems.",
      "3-tier": "Foundation",
      "3-points": "3",
      "3-conversation" : "",
      "3-recommendation" : "Start by identifying sensitive data and classifying it based on importance and sensitivity. Utilise role-based access control (RBAC) or attribute-based access control (ABAC) to enforce granular access controls. Implement least privilege principles to restrict access to only necessary data and functions. ",
      "4": "Tokenization",
      "4-summary": "Tokenization is the process of substituting sensitive data elements with non-sensitive equivalents, or tokens, that have no exploitable meaning or value. This method secures data by ensuring that the original information can only be retrieved through a specific mapping system, effectively protecting it during storage and transmission while reducing the risk of data breaches.",
      "4-tier": "Strategic",
      "4-points": "4",
      "4-conversation" : "",
      "4-recommendation" : "Start by identifying sensitive data elements such as personally identifiable information (PII) and payment card information (PCI). Utilise tokenization solutions to replace sensitive data with non-sensitive tokens. Implement strong encryption mechanisms to protect both the data and the tokens. ",
      "5": "Loss Prevention",
      "5-summary": "Data Loss Prevention (DLP) is a set of tools and processes designed to identify, monitor, and protect sensitive data to prevent unauthorised access and leaks. This approach ensures that critical information is not misused, misplaced, or accessed by unauthorised individuals, safeguarding an organization's data against loss or theft.",
      "5-tier": "Strategic",
      "5-points": "5",
      "5-conversation" : "",
      "5-recommendation" : "Start by identifying sensitive data and where it resides within your organization. Utilise DLP solutions to monitor, detect, and prevent unauthorised data exfiltration or leakage. Implement policies and controls to monitor data movement and enforce encryption where necessary.",
      "6": "Automated Posture Management",
      "6-summary": "Automated Data Security Posture Management utilises technology to continuously monitor, evaluate, and enhance the security stance of an organization's data across all environments. It automates the identification and correction of data security risks, ensuring compliance with policies and regulations, thereby minimizing the potential for data breaches and enhancing data protection efforts.",
      "6-tier": "Strategic",
      "6-points": "6",
      "6-conversation" : "",
      "6-recommendation" : "Start by assessing your current data security posture and identifying potential gaps and vulnerabilities. Utilise automated tools to continuously monitor and assess your data security controls. Implement automated remediation actions to address security issues promptly.",
      "7": "Immutable Storage",
      "7-summary": "Immutable storage is a data storage approach that prevents data from being altered or deleted after it has been written, ensuring the integrity and permanence of the stored information. This method is crucial for regulatory compliance, data protection, and ensuring the reliability of backup and archival systems, as it safeguards against data tampering and ransomware attacks.",
      "7-tier": "Advanced",
      "7-points": "7",
      "7-conversation" : "",
      "7-recommendation" : "Start by identifying critical data that requires protection against unauthorised alteration or deletion. Utilise storage solutions that support immutable storage capabilities. Implement strict access controls to ensure only authorised users can modify or delete data.",
      "8": "Anomaly Detection",
      "8-summary": "Anomaly detection involves identifying patterns or activities within a data set that deviate from the expected behavior, signaling potential issues such as security breaches, fraud, or system failures. This process is essential for early threat detection and response, helping organizations to proactively address vulnerabilities and protect against malicious activities.",
      "8-tier": "Advanced",
      "8-points": "8",
      "8-conversation" : "",
      "8-recommendation" : "Start by establishing baseline behavior for normal system operation. Utilise machine learning algorithms to identify deviations from this baseline. Implement real-time monitoring and alerting to promptly identify and respond to anomalous behavior. Regularly review and update anomaly detection models to adapt to evolving threats and changes in your IT environment."
      },
    "SecureIdentity" : {
      "overview" : "Secure Identity involves verifying and managing the digital identities of users accessing systems, networks, and applications to prevent unauthorised access and ensure trustworthiness. It encompasses techniques such as multi-factor authentication, biometrics, and identity federation to authenticate users securely and authorise access based on their roles and permissions. By implementing robust identity management practices, organizations can reduce the risk of identity theft, fraud, and unauthorised access to sensitive information.",
      "qnum" : "3",
      "title" : "Secure Identity",
      "1": "Passwords",
      "1-summary": "Passwords are secret character sequences used to authenticate and gain access to resources or data, serving as a fundamental aspect of digital security by verifying the identity of users. They play a critical role in protecting user accounts and sensitive information from unauthorised access, making strong, unique passwords essential for maintaining security and privacy in digital environments.",
      "1-tier": "Foundation",
      "1-points": "1",
      "1-conversation" : "",
      "1-recommendation" : "Start by enforcing Strong Passwords which require passwords with a mix of letters, numbers, and special characters. After this, implement Multi-Factor Authentication (MFA) to add an extra layer of security",
      "2": "Role-Based Access Control",
      "2-summary": "Role-Based Access Control (RBAC) is a method of restricting system access to authorised users based on their roles within an organization. It simplifies management and enforcement of enterprise-wide access policies by assigning permissions to roles, rather than individuals, ensuring that users have access only to the information and resources necessary for their duties, thereby enhancing security and operational efficiency.",
      "2-tier": "Foundation",
      "2-points": "2",
      "2-conversation" : "",
      "2-recommendation" : "When implementing Role-Based Access Control (RBAC), define the different roles within your organization based on job responsibilities. Then assign specific permissions to each role based on their job requirements and ensure each role has only the minimum permissions necessary to perform its function.  Periodically review and update role assignments to align with organizational changes and monitor user access and regularly audit permissions to ensure compliance and security.",
      "3": "Multi-Factor Identification",
      "3-summary": "Multi-Factor Authentication (MFA) is a security mechanism that requires users to provide two or more verification factors to gain access to a resource, such as an application, online account, or a VPN. By combining something the user knows (like a password), something the user has (like a smartphone app or hardware token), and something the user is (like a fingerprint or facial recognition), MFA significantly enhances security by adding layers of defense against unauthorised access and breaches.",
      "3-tier": "Foundation",
      "3-points": "3",
      "3-conversation" : "",
      "3-recommendation" : "Start by requiring users to provide two or more authentication factors to verify their identity. This typically includes something the user knows (like a password), something the user has (like a smartphone or token), and something the user is (like a fingerprint). By requiring multiple factors, MFA adds an extra layer of security, making it significantly more difficult for unauthorised users to gain access to accounts and sensitive information.",
      "4": "Single Sign On",
      "4-summary": "Single Sign-On (SSO) is an authentication process that allows a user to access multiple applications or systems with one set of credentials, simplifying the user experience by reducing the number of times a user needs to log in. SSO enhances both convenience and security by minimizing password fatigue and the risk of phishing, as it reduces the number of login prompts and credentials users must manage.",
      "4-tier": "Strategic",
      "4-points": "4",
      "4-conversation" : "",
      "4-recommendation" : "Aim to streamline user authentication by allowing them to access multiple applications with just one set of login credentials. By integrating SSO, users can authenticate once and gain access to all authorised applications and resources without having to log in again for each one. This not only enhances user experience but also improves security by reducing the need for users to manage multiple passwords. Additionally, SSO simplifies access management for IT administrators, allowing them to centrally manage user access and permissions across all integrated applications.",
      "5": "Privileged Access Management",
      "5-summary": "Privileged Access Management (PAM) is a critical security framework that controls, monitors, and manages access to an organization's critical information and resources by privileged users, such as administrators and IT personnel. PAM helps prevent security breaches by securing, auditing, and limiting the actions and reach of privileged accounts through stringent authentication methods, access controls, and user activity tracking, ensuring only authorised and authenticated users can access sensitive systems and data.",
      "5-tier": "Strategic",
      "5-points": "5",
      "5-conversation" : "",
      "5-recommendation" : "Prioritise securing access to critical systems and sensitive data by strictly controlling and monitoring privileged accounts. Start by identifying all privileged accounts and implementing strict access controls, such as least privilege principles and just-in-time access. Utilise PAM solutions to enforce strong authentication, session monitoring, and privilege elevation. Regularly review and audit privileged access to detect and respond to any unauthorised or suspicious activity.",
      "6": "Identity Federation",
      "6-summary": "Identity Federation is a system of trust that allows organizations to share identity information across multiple and diverse security domains, enabling users to access applications and services across different systems using a single set of credentials. This approach streamlines user access to a wide range of resources without the need for multiple usernames and passwords, enhancing user convenience while maintaining strict security and privacy standards through centralised authentication and authorization processes.",
      "6-tier": "Strategic",
      "6-points": "6",
      "6-conversation" : "",
      "6-recommendation" : "Focus on enabling seamless and secure access to resources across multiple domains or organizations. By federating identities, users can access services and applications using their existing credentials from their home domain. Implementing Identity Federation involves establishing trust relationships between identity providers and service providers, allowing users to authenticate once and access multiple services without needing separate credentials.",
      "7": "AI/ML Anomaly Detection",
      "7-summary": "AI/ML anomaly detection leverages artificial intelligence and machine learning algorithms to automatically analyze data patterns and identify deviations from the norm, signaling potential issues such as fraud, security breaches, or operational disruptions. This advanced approach enables real-time detection and response to sophisticated threats, significantly enhancing the accuracy and efficiency of security operations by learning from data trends and adapting to new anomalies over time.",
      "7-tier": "Advanced",
      "7-points": "7",
      "7-conversation" : "",
      "7-recommendation" : "Start by collecting and analyzing large volumes of data to establish baseline behavior. Utilise machine learning algorithms to identify deviations from this baseline, which could indicate potential security threats or operational issues. Implement real-time monitoring and alerting to promptly identify and respond to anomalous behavior. Regularly update and fine-tune anomaly detection models to adapt to evolving threats and changes in your IT environment.",
      "8": "Contextual / Risk Based Access",
      "8-summary": "Contextual or Risk-Based Access Control (RBAC) is a dynamic approach to managing user access that evaluates the risk associated with each access request based on the context of the situation. Factors such as user location, device security status, time of access, and the sensitivity of the accessed data are considered to adjust authentication requirements and access permissions in real-time. This method enhances security by adapting protections based on the assessed risk level of a transaction or access attempt, ensuring stricter controls are applied in higher-risk scenarios.",
      "8-tier": "Advanced",
      "8-points": "8",
      "8-conversation" : "",
      "8-recommendation" : "Focus on dynamically adjusting access permissions based on the level of risk associated with the user and the context of their access request. Utilise risk assessment techniques to evaluate factors such as user behavior, device posture, location, and the sensitivity of the resource being accessed. Implement policies that automatically adjust access privileges in real-time based on the assessed risk level. "
    },
    "SecureApplication" : {
      "overview" : "Secure Applications refer to software programs and systems that are developed and maintained with a focus on mitigating security risks and vulnerabilities. This involves implementing secure coding practices, regular security assessments, and patch management to prevent exploitation by malicious actors. By prioritizing security throughout the software development lifecycle, organizations can ensure that their applications resist attacks and protect sensitive data from unauthorised access or manipulation.",
      "qnum" : "4",
      "title" : "Secure Application",
      "1": "Dependency Management",
      "1-summary": "Application dependency management involves the process of identifying, tracking, and controlling the libraries and components an application relies on to function properly. This includes ensuring compatibility between different versions of dependencies, managing updates to mitigate security vulnerabilities, and minimizing conflicts that can arise from incompatible or outdated components. Effective dependency management is crucial for maintaining the stability, security, and reliability of software applications, as it helps developers to manage the complexities associated with integrating external software components.",
      "1-tier": "Foundation",
      "1-points": "1",
      "1-conversation" : "",
      "1-recommendation" : "Begin by identifying the dependencies and relationships between different components of your application stack. Utilise tools and techniques to map out these dependencies, including libraries, APIs, databases, and external services. Establish processes for managing and updating dependencies, ensuring compatibility and security. Regularly review and update dependency maps to reflect changes in your application architecture.",
      "2": "Static Application Security Testing",
      "2-summary": "Static Application Security Testing (SAST) is a type of security testing that analyzes source code, bytecode, or binary code for vulnerabilities that could lead to security breaches, without executing the application. It identifies issues such as input validation errors, insecure dependencies, and potential backdoors early in the software development lifecycle, allowing developers to address vulnerabilities before deployment. SAST is an essential component of secure coding practices, helping to ensure that applications are built with security in mind from the ground up.",
      "2-tier": "Foundation",
      "2-points": "2",
      "2-conversation" : "",
      "2-recommendation" : "Integrate automated code analysis tools into the software development lifecycle to identify security vulnerabilities in the source code. Conduct static analysis to identify potential security flaws, such as injection attacks, authentication issues, and sensitive data exposure. Integrate SAST into the development process, performing regular scans during code development and before deployment.",
      "3": "Secure Code Practices",
      "3-summary": "Secure coding practices involve adopting standards and guidelines to write software code that is resistant to vulnerabilities and attacks. These practices encompass validating input, sanitizing output, managing errors securely, implementing proper authentication and authorization checks, and encrypting sensitive data. By integrating security into the development process from the beginning, secure coding practices help prevent common security flaws, ensuring that software is robust against unauthorised access and exploitation, thereby protecting both the applications and the data they process.",
      "3-tier": "Foundation",
      "3-points": "3",
      "3-conversation" : "",
      "3-recommendation" : "Prioritise security throughout the software development lifecycle. Provide developers with training and resources on secure coding practices, including input validation, output encoding, and proper error handling. Utilise automated tools for code review and vulnerability scanning to identify and remediate security issues early in the development process. Enforce secure coding standards and conduct regular security reviews to ensure compliance.",
      "4": "Dynamic Application Security Testing",
      "4-summary": "Dynamic Application Security Testing (DAST) is a security testing methodology that assesses an application from the outside in, by testing it in its running state. This approach is used to identify vulnerabilities that an attacker could exploit, such as issues related to the execution environment or runtime issues that can't be detected through static analysis. DAST tools simulate attacks on a web application to find security weaknesses and are effective in identifying runtime problems, such as authentication and authorization issues, session management problems, and vulnerabilities to cross-site scripting (XSS) or SQL injection attacks.",
      "4-tier": "Strategic",
      "4-points": "4",
      "4-conversation" : "",
      "4-recommendation" : "Utilise automated tools to scan running web applications for security vulnerabilities. Conduct dynamic analysis by simulating attacks and analyzing application responses to identify potential vulnerabilities, such as injection flaws, cross-site scripting (XSS), and broken authentication. Integrate DAST into the software development lifecycle, performing regular scans during development and before deployment.",
      "5": "Web Application Firewall",
      "5-summary": "A Web Application Firewall (WAF) is a security solution that monitors, filters, and blocks HTTP/S traffic to and from a web application to protect against malicious attempts to compromise the system or exfiltrate data. By applying a set of rules to web traffic, WAF can prevent common web vulnerabilities such as SQL injection, cross-site scripting (XSS), and file inclusion attacks, among others. It acts as a shield between the web application and the internet, providing a critical layer of security for web applications by inspecting incoming traffic for malicious patterns and blocking potential threats.",
      "5-tier": "Strategic",
      "5-points": "5",
      "5-conversation" : "",
      "5-recommendation" : "Deploy a security appliance or service at the edge of your network to monitor and filter HTTP/HTTPS traffic between a web application and the internet. Configure the WAF to inspect incoming traffic and block malicious requests, such as SQL injection, cross-site scripting (XSS), and other common web application attacks. Customise WAF rules to match the specific security requirements of your web application. Regularly update and fine-tune WAF configurations to adapt to evolving threats.",
      "6": "Container Scanning",
      "6-summary": "Container scanning is a security practice that involves examining container images for vulnerabilities, misconfigurations, and security best practices violations before they are deployed to production. This process helps identify and remediate security issues early in the development cycle, reducing the risk of deploying containers with known vulnerabilities. Container scanning tools analyze the contents of container images, including the base image, added packages, and the application itself, to provide insights into potential security weaknesses and compliance with security policies, thereby ensuring that containers are secure and ready for deployment.",
      "6-tier": "Strategic",
      "6-points": "6",
      "6-conversation" : "",
      "6-recommendation" : "Integrate automated scanning tools into your continuous integration and continuous deployment (CI/CD) pipeline to identify security vulnerabilities and misconfigurations in container images. Conduct static and dynamic analysis of container images to detect known vulnerabilities, insecure dependencies, and compliance issues. Utilise scanning tools to assess the risk level of each vulnerability and prioritise remediation efforts. Integrate container scanning into your DevSecOps practices, performing regular scans throughout the development lifecycle.",
      "7": "Runtime Application Self Protection",
      "7-summary": "Runtime Application Self-Protection (RASP) is a security technology that integrates with an application or its runtime environment to detect and prevent attacks in real time. RASP does this by continuously monitoring the application's behavior and the context of that behavior. When it identifies potentially malicious activities, it can take immediate action to mitigate the threat. This can include terminating a session, alerting administrators, or even modifying the application's response to prevent exploitation. RASP offers an added layer of protection by working from within the application, providing detailed insight into its data flow and logic, and enabling precise defense mechanisms against attacks without requiring changes to the application's code.",
      "7-tier": "Advanced",
      "7-points": "7",
      "7-conversation" : "",
      "7-recommendation" : "Embed security monitoring and protection mechanisms directly into your application runtime environment. Utilise RASP solutions to continuously monitor application behavior and detect and block suspicious activities, such as injection attacks, unauthorised access, and data leakage. Configure RASP policies to automatically respond to security threats in real-time, such as blocking malicious requests or logging security events. Integrate RASP into your application stack to provide an additional layer of security that complements existing perimeter defenses.",
      "8": "Interactive Application Security Testing",
      "8-summary": "Interactive Application Security Testing (IAST) is a security testing approach that combines elements of both static application security testing (SAST) and dynamic application security testing (DAST) to detect vulnerabilities in applications. IAST tools are designed to be integrated into the application runtime environment, where they can observe and analyze application behavior and data flow in real-time as the application interacts with users or automated tests. This method allows for the detection of security issues that are only evident during the application's execution, such as runtime injection attacks or authentication problems. By providing immediate feedback to developers, IAST facilitates the rapid identification and remediation of security vulnerabilities within the software development lifecycle, enhancing the application's overall security posture.",
      "8-tier": "Advanced",
      "8-points": "8",
      "8-conversation" : "",
      "8-recommendation" : "Integrate security testing tools directly into your application runtime environment to identify vulnerabilities in real-time. IAST solutions monitor application behavior during runtime and automatically detect security vulnerabilities, such as SQL injection, cross-site scripting (XSS), and other common web application attacks. By analyzing application behavior in real-time, IAST provides more accurate results compared to traditional static or dynamic analysis tools. Integrate IAST into your continuous integration and continuous deployment (CI/CD) pipeline to ensure that security vulnerabilities are identified and remediated early in the development lifecycle. "
    },  
    "SecureNetwork" : {
      "overview" : "Secure Network involves implementing measures to protect networks and data transmission from unauthorised access, interception, or tampering. This includes deploying firewalls, intrusion detection systems, and virtual private networks (VPNs) to safeguard communication channels and prevent external threats. By enforcing encryption protocols, segmenting networks, and regularly updating security configurations, organizations can maintain the integrity and confidentiality of their network infrastructure.",
      "qnum" : "5",
      "title" : "Secure Network",
      "1": "Firewalls & Segmentation",
      "1-summary": "Network firewalls act as a barrier to control access between trusted and untrusted networks, using predefined rules to block or allow traffic. Network segmentation divides a network into smaller, isolated segments to limit the spread of threats and enforce specific security policies, enhancing overall security and reducing the attack surface.",
      "1-tier": "Foundation",
      "1-points": "1",
      "1-conversation" : "",
      "1-recommendation" : "Start by defining your network's critical assets and sensitive data. Deploy firewalls to monitor and control traffic between network segments, ensuring that only authorised traffic is allowed. Implement data segmentation to separate sensitive data from the rest of the network, limiting access to authorised users and systems. Utilise a combination of network and host-based firewalls to provide multiple layers of defence. Regularly review and update firewall rules and segmentation policies to adapt to evolving threats and changes in your network infrastructure.",
      "2": "Secure Protocols",
      "2-summary": "Secure network protocols, such as HTTPS, SSL/TLS, and SSH, are designed to encrypt data in transit, ensuring confidentiality, integrity, and authentication between communicating devices. These protocols protect sensitive information from eavesdropping, tampering, and impersonation attacks, making them essential for secure communications over untrusted networks like the internet.",
      "2-tier": "Foundation",
      "2-points": "2",
      "2-conversation" : "",
      "2-recommendation" : "Prioritise the use of encryption and authentication to protect data in transit. Utilise protocols such as Transport Layer Security (TLS) and Secure Shell (SSH) to encrypt communications and authenticate users. Ensure that all network devices and services are configured to use secure protocols by default. Regularly update and patch network equipment to mitigate known vulnerabilities.",
      "3": "Access Control Lists",
      "3-summary": "Access Control Lists (ACLs) are a set of rules that control the access to network resources, specifying which users or system processes are granted access to objects, as well as what operations are allowed on given objects. They play a crucial role in defining permissions and enhancing security by explicitly allowing or denying traffic flow to and from specific addresses, ports, or protocols within a network.",
      "3-tier": "Foundation",
      "3-points": "3",
      "3-conversation" : "",
      "3-recommendation" : "Start by defining the traffic that should be allowed or denied on your network devices. Utilise ACLs to filter and control traffic based on IP addresses, protocols, and ports. Implement ACLs on routers, switches, and firewalls to restrict access to network resources and protect against unauthorised access and network attacks. Regularly review and update ACLs to ensure they align with security policies and effectively mitigate risks.",
      "4": "Intrusion Detection / Prevention",
      "4-summary": "Intrusion Detection Systems (IDS) and Intrusion Prevention Systems (IPS) are critical components of network security that monitor network traffic to detect and respond to malicious activities. IDS systems analyze traffic for signs of attacks and generate alerts, whereas IPS systems actively block detected threats in real time, preventing potential damage to the network infrastructure.",
      "4-tier": "Strategic",
      "4-points": "4",
      "4-conversation" : "",
      "4-recommendation" : "Deploy sensors across your network to monitor and analyse traffic for signs of malicious activity or security policy violations. Utilise IDS to detect and alert on suspicious behaviour, such as unauthorised access attempts, malware activity, or abnormal traffic patterns. Configure IDS to generate alerts and notifications for security incidents, enabling prompt response and mitigation. Regularly review and analyse IDS alerts to identify security threats and vulnerabilities.",
      "5": "Traffic Analysis",
      "5-summary": "Traffic analysis involves the systematic examination of data packets flowing through a network to identify patterns, detect anomalies, and understand behavior. This process is essential for optimizing network performance, ensuring security by identifying potential threats, and aiding in troubleshooting by pinpointing sources of problems within network traffic.",
      "5-tier": "Strategic",
      "5-points": "5",
      "5-conversation" : "",
      "5-recommendation" : "Deploy monitoring tools to capture and analyse network traffic in real-time. Utilise traffic analysis to identify and investigate abnormal patterns, potential security threats, and performance issues. Configure traffic analysis tools to generate alerts for suspicious activities, such as unusual data transfers or network reconnaissance. Regularly review and analyse traffic logs to detect and respond to security incidents promptly.",
      "6": "Secure Connections",
      "6-summary": "Secure connections refer to communication channels established between two endpoints, such as devices or servers, that are protected against eavesdropping, tampering, and unauthorised access. These connections typically use cryptographic protocols like SSL/TLS to encrypt data in transit, ensuring confidentiality, integrity, and authentication of the transmitted information, thereby safeguarding sensitive data from interception or manipulation by malicious actors.",
      "6-tier": "Strategic",
      "6-points": "6",
      "6-conversation" : "",
      "6-recommendation" : "Prioritise the use of encryption and authentication to protect data in transit. Utilise protocols such as Transport Layer Security (TLS) and Secure Shell (SSH) to encrypt communications and authenticate users. Ensure that all network devices and services are configured to use secure protocols by default. Regularly update and patch network equipment to mitigate known vulnerabilities.",
      "7": "Microsegmentation",
      "7-summary": "Microsegmentation is a network security strategy that involves dividing a network into smaller, isolated segments to enhance security by enforcing stricter access controls and policies between individual workloads or applications. By implementing fine-grained segmentation, organizations can limit lateral movement of threats, reduce the attack surface, and minimise the impact of breaches by containing them within isolated segments, thereby improving overall security posture.",
      "7-tier": "Advanced",
      "7-points": "7",
      "7-conversation" : "",
      "7-recommendation" : "Start by dividing your network into smaller, isolated segments to limit the lateral movement of attackers. Utilise firewalls and access control lists (ACLs) to control traffic between these segments based on specific security policies. Implement microsegmentation to restrict access to sensitive data and critical systems, reducing the attack surface and limiting the impact of security breaches.",
      "8": "Zero Trust Network Access",
      "8-summary": "Zero Trust Network Access (ZTNA) is a security model that assumes no trust for any user or device inside or outside the corporate network perimeter. Instead of relying on traditional network perimeters, ZTNA verifies every user and device attempting to connect to resources, regardless of their location, before granting access based on policies and contextual factors. This approach minimises the risk of unauthorised access and lateral movement of threats, providing a more robust and adaptive security posture in today's dynamic and distributed IT environments.",
      "8-tier": "Advanced",
      "8-points": "8",
      "8-conversation" : "",
      "8-recommendation" : "Adopt a strict access control model that verifies each user and device attempting to connect to the network, regardless of whether they are inside or outside the network perimeter. Utilise identity and device authentication, as well as continuous monitoring, to ensure only authorised users and devices can access network resources. Implement granular access controls based on user identity, device security posture, and contextual factors."
        },
    "SecureRecovery" : {
      "qnum" : "6",
      "overview" : "Secure Recovery refers to the process of restoring a system to a functional state after a disruption or compromise while ensuring the integrity and security of the recovered environment. It involves creating backups of critical data, implementing recovery procedures, and validating the authenticity of recovery components to prevent further damage or exploitation. By following secure recovery practices, organizations can minimise downtime, mitigate risks, and maintain trust in their systems' resilience against potential threats.",
      "title" : "Secure Recovery",
      "1": "Backup & Redundancy",
      "1-summary": "Backups and redundancy are essential components of data protection and disaster recovery strategies, ensuring the availability, integrity, and resilience of critical data and systems. Backups involve creating copies of data and storing them in separate locations to mitigate the risk of data loss due to hardware failures, human errors, or cyberattacks. Redundancy, on the other hand, involves deploying duplicate hardware, networks, or services to provide failover capabilities and maintain continuous operation in the event of component failures or disruptions. Together, backups and redundancy help organizations minimise downtime, recover quickly from disasters, and maintain business continuity.",
      "1-tier": "Foundation",
      "1-points": "1",
      "1-conversation" : "",
      "1-recommendation" : "Ensure regular and automated backups of critical data and systems are in place. Utilise redundant hardware, network connections, and data centres to minimise the risk of single points of failure. Regularly test backup and redundancy systems to verify their effectiveness and reliability. Implement off-site or cloud-based backups to protect against physical damage or loss.",
      "2": "Disaster Recovery Plan",
      "2-summary": "A Disaster Recovery Plan (DRP) is a documented set of procedures and strategies designed to recover and restore IT infrastructure, systems, and data in the event of a disaster or disruptive incident. It outlines the steps to be taken before, during, and after a disaster to minimise downtime, mitigate risks, and ensure business continuity. DRPs typically include measures such as data backups, redundancy, failover mechanisms, and recovery processes tailored to specific scenarios, ensuring organizations can respond effectively to disruptions and resume critical operations with minimal impact.",
      "2-tier": "Foundation",
      "2-points": "2",
      "2-conversation" : "",
      "2-recommendation" : "Start by identifying critical systems, data, and processes within your organisation. Develop a comprehensive plan that outlines procedures for responding to various disaster scenarios, such as natural disasters, cyber attacks, or hardware failures. Establish recovery time objectives (RTOs) and recovery point objectives (RPOs) to guide the recovery process. Regularly test and update the DRP to ensure its effectiveness and reliability.",
      "3": "Consistent Versioning",
      "3-summary": "Consistent versioning is a practice of systematically managing and documenting changes to software, files, or documents by assigning unique identifiers or labels to each iteration or release. This enables users to track and reference specific versions, ensuring clarity, accuracy, and accountability throughout the development or revision process. Consistent versioning facilitates collaboration, rollback capabilities, and the ability to compare different versions, fostering efficient development, maintenance, and quality assurance practices.",
      "3-tier": "Foundation",
      "3-points": "3",
      "3-conversation" : "",
      "3-recommendation" : "Establish a clear and structured approach to versioning software releases. Utilise a standardised numbering system that reflects the significance of changes made in each version, such as semantic versioning (Major.Minor.Patch). Implement version control systems to manage code changes and track version history. Communicate versioning conventions to all stakeholders to ensure clarity and consistency. ",
      "4": "Automated Failovers",
      "4-summary": "Automated failovers are mechanisms implemented in IT systems to automatically redirect traffic or workload from a failed or impaired component to a healthy one without manual intervention. This ensures continuous operation and minimises downtime by swiftly responding to hardware failures, network disruptions, or other system faults. Automated failovers rely on predefined triggers, monitoring systems, and orchestrated processes to swiftly detect and mitigate issues, thereby maintaining service availability and enhancing overall resilience and reliability of the system.",
      "4-tier": "Strategic",
      "4-points": "4",
      "4-conversation" : "",
      "4-recommendation" : "Utilise tools and scripts to detect system failures and automatically switch to backup systems or redundant resources without manual intervention. Configure monitoring systems to detect service disruptions or performance degradation and trigger failover processes when necessary. Test failover mechanisms regularly to ensure they function as expected and do not disrupt normal operations.",
      "5": "Lifecycle Management",
      "5-summary": "Identity lifecycle management is the process of managing the entire lifecycle of user identities within an organization, from creation to retirement. It involves various stages such as provisioning, deprovisioning, authentication, authorization, and maintenance of user accounts and permissions. Identity lifecycle management ensures that users have appropriate access to resources based on their roles and responsibilities, while also addressing security, compliance, and efficiency requirements throughout the user's tenure within the organization.",
      "5-tier": "Strategic",
      "5-points": "5",
      "5-conversation" : "",
      "5-recommendation" : "Establish processes to manage software from its initial development to its retirement. Utilise version control systems to track changes and manage code repositories effectively. Implement release management processes to plan, schedule, and deploy software releases systematically. Regularly update and patch software to address security vulnerabilities and ensure compatibility with evolving requirements.",
      "6": "Storage Scanning & Monitoring",
      "6-summary": "Storage scanning refers to the process of systematically inspecting data storage systems, such as disks, file servers, or cloud repositories, to identify and mitigate security risks, vulnerabilities, or malicious activities. This includes scanning for malware, unauthorised access, data leaks, or other anomalies that may compromise the integrity, confidentiality, or availability of stored data. Storage scanning tools employ various techniques such as signature-based detection, behavioral analysis, and heuristic algorithms to proactively identify and remediate potential threats, ensuring the security and compliance of data storage environments.",
      "6-tier": "Strategic",
      "6-points": "6",
      "6-conversation" : "",
      "6-recommendation" : "Utilise automated tools to regularly scan storage systems for security vulnerabilities, malware, and unauthorised access. Implement real-time monitoring to detect and alert on suspicious activities, such as unauthorised file access or changes. Utilise logging and auditing to track storage system activity and identify potential security threats. Regularly review and update scanning and monitoring configurations to adapt to evolving security threats.",
      "7": "Advanced Key Management",
      "7-summary": "Advanced key management involves the sophisticated handling and protection of cryptographic keys used to secure sensitive data and communications. This includes the generation, storage, distribution, rotation, and destruction of encryption keys in a manner that maximises security and minimises risks. Advanced key management solutions often incorporate features such as key lifecycle management, secure key storage, role-based access controls, key rotation policies, and integration with hardware security modules (HSMs) or cloud-based key management services. These measures ensure that cryptographic keys are properly managed and safeguarded throughout their lifecycle, maintaining the confidentiality, integrity, and availability of encrypted data.",
      "7-tier": "Advanced",
      "7-points": "7",
      "7-conversation" : "",
      "7-recommendation" : "Utilise robust encryption key management practices to protect sensitive data effectively. Implement key management solutions that provide centralised control over encryption keys, including generation, storage, rotation, and deletion. Utilise hardware security modules (HSMs) to securely generate and store encryption keys and perform cryptographic operations. Implement key rotation and revocation processes to ensure the security of encrypted data over time.",
      "8": "Predictive Recovery",
      "8-summary": "Predictive identity recovery is a concept that involves leveraging data analytics and machine learning algorithms to proactively detect and respond to identity-related issues or breaches before they escalate. By analyzing historical data, user behavior patterns, and access logs, predictive identity recovery solutions can identify anomalous activities or indicators of compromised identities. This enables organizations to take preemptive action, such as resetting compromised credentials, revoking unauthorised access, or initiating security incident response procedures, to mitigate potential risks and prevent further damage to the organization's security posture. Predictive identity recovery enhances security by enabling organizations to stay ahead of emerging threats and proactively protect their identities and data assets.",
      "8-tier": "Advanced",
      "8-points": "8",
      "8-conversation" : "",
      "8-recommendation" : "Utilise data analytics and machine learning algorithms to proactively identify and mitigate potential data loss risks. Analyse historical data and user behaviour patterns to predict and prevent data loss incidents before they occur. Implement automated data recovery mechanisms to restore lost or corrupted data quickly. Regularly test and validate predictive data recovery processes to ensure their effectiveness."
        },
    "SecureOperations" : {
      "overview" : "Secure Operations involves the implementation of policies, procedures, and technologies to ensure the ongoing security and integrity of an organization's systems and processes. This encompasses practices such as continuous monitoring, incident response planning, and security awareness training to detect and mitigate threats effectively. By integrating security into every aspect of operations, organizations can minimise risks, protect assets, and maintain the trust of stakeholders.",
      "qnum" : "7",
      "title" : "Secure Operations",
      "1": "Incident Response Plan",
      "1-summary": "A security incident response plan (IRP) outlines the procedures and protocols to be followed in the event of a security breach or incident. It provides a structured approach for identifying, containing, mitigating, and recovering from security breaches, minimizing the impact on the organization and ensuring a swift and effective response to security threats.",
      "1-tier": "Foundation",
      "1-points": "1",
      "1-conversation" : "",
      "1-recommendation" : "Establish clear procedures for detecting, responding to, and recovering from security incidents. Define roles and responsibilities for incident response team members and establish communication channels for reporting and escalating incidents. Develop predefined response actions for different types of security incidents, such as data breaches, malware infections, or denial-of-service attacks. Regularly test and update the IRP to ensure its effectiveness and alignment with evolving security threats.",
      "2": "Anti-Virus scan",
      "2-summary": "An antivirus scan is a process that involves systematically examining files, programs, or systems for known malware or malicious code patterns. It helps detect and remove viruses, worms, Trojans, and other types of malware to prevent them from compromising the security and integrity of computer systems and data.",
      "2-tier": "Foundation",
      "2-points": "2",
      "2-conversation" : "",
      "2-recommendation" : "Utilise automated scanning tools to regularly scan all endpoints, servers, and network devices for malware and other security threats. Schedule regular scans during off-peak hours to minimise disruption to business operations. Configure antivirus software to update virus definitions automatically to detect the latest threats. Implement centralised management and reporting to monitor scan results and take action on detected threats promptly.",
      "3": "Security Information & Event Management",
      "3-summary": "SIEM, or Security Information and Event Management, is a comprehensive approach to security management that combines security information management (SIM) and security event management (SEM) functions. It involves collecting, correlating, analyzing, and reporting on security events and data from various sources across an organization's IT infrastructure, enabling real-time threat detection, incident response, and regulatory compliance. SIEM systems provide organizations with centralised visibility into their security posture, helping them identify and respond to security incidents more effectively.",
      "3-tier": "Foundation",
      "3-points": "3",
      "3-conversation" : "",
      "3-recommendation" : "Deploy a centralised platform to collect, analyse, and correlate security event data from across your organisation's network and IT infrastructure. Configure SIEM rules and alerts to detect and respond to security incidents in real-time. Utilise machine learning and analytics to identify patterns and anomalies indicative of security threats. Implement user behaviour analytics (UBA) to detect insider threats and suspicious activity. ",
      "4": "Endpoint Detection & Response",
      "4-summary": "Endpoint Detection and Response (EDR) is a cybersecurity technology that focuses on monitoring and responding to suspicious activities and threats on endpoints, such as desktops, laptops, servers, and mobile devices. EDR solutions continuously collect and analyze endpoint data, including process behavior, file activity, network connections, and system events, to detect indicators of compromise (IOCs) and potential security breaches. By providing real-time visibility and advanced threat detection capabilities, EDR helps organizations quickly identify and mitigate security incidents, enhancing overall endpoint security posture and reducing the risk of data breaches.",
      "4-tier": "Strategic",
      "4-points": "4",
      "4-conversation" : "",
      "4-recommendation" : "Deploy endpoint security solutions to monitor, detect, and respond to security threats on individual devices. Utilise EDR tools to collect and analyse endpoint activity in real-time, identifying and investigating suspicious behaviour and security incidents. Configure automated response actions to contain and remediate threats promptly. Implement centralised management and reporting to monitor endpoint security across the organisation.",
      "5": "Orchestration, Automation, Response",
      "5-summary": "SOAR, or Security Orchestration, Automation, and Response, is a cybersecurity approach that integrates security orchestration and automation capabilities with incident response processes. It enables organizations to streamline and automate repetitive security tasks, such as alert triage, investigation, and response, by orchestrating workflows across disparate security tools and systems. By automating routine tasks and standardizing incident response procedures, SOAR platforms help security teams improve efficiency, reduce response times, and better manage the increasing volume and complexity of security alerts and incidents.",
      "5-tier": "Strategic",
      "5-points": "5",
      "5-conversation" : "",
      "5-recommendation" : "Deploy a centralised platform to automate and streamline security operations. Utilise SOAR tools to integrate security technologies, orchestrate incident response workflows, and automate repetitive tasks. Configure playbooks to standardise incident response processes and automate response actions. Implement machine learning and analytics to identify patterns and anomalies indicative of security threats. Regularly review and update SOAR configurations to adapt to evolving security threats.",
      "6": "Threat Intelligence Integration",
      "6-summary": "Threat Intelligence Platform (TIP) Integration involves the incorporation of external threat intelligence feeds and data sources into an organization's security infrastructure and processes. This integration enables security teams to enhance their threat detection and response capabilities by leveraging up-to-date information about emerging threats, vulnerabilities, and attacker tactics, techniques, and procedures (TTPs). By integrating threat intelligence feeds with security tools such as SIEMs, EDR solutions, and SOAR platforms, organizations can enrich their security telemetry, automate threat detection and analysis, and prioritise and remediate security incidents more effectively.",
      "6-tier": "Strategic",
      "6-points": "6",
      "6-conversation" : "",
      "6-recommendation" : "Deploy a centralised platform to collect, analyse, and disseminate threat intelligence data from various sources. Utilise TIP tools to correlate threat data with your organisation's network and security events, identifying potential security threats and vulnerabilities. Implement automated threat feeds to stay updated on the latest threat intelligence. Configure alerting and reporting to notify security teams of emerging threats.",
      "7": "APT Detection & Response",
      "7-summary": "APT (Advanced Persistent Threat) Detection and Response refers to the strategies, technologies, and processes used to identify and mitigate Advanced Persistent Threats (APTs), which are sophisticated and targeted cyber attacks typically orchestrated by well-funded and organised threat actors. APT detection involves leveraging advanced threat detection techniques, such as behavioral analytics, anomaly detection, and threat intelligence, to identify indicators of compromise (IOCs) associated with APT activity. APT response encompasses the coordinated efforts to contain, investigate, and remediate APT attacks, often involving incident response teams, threat hunters, and security technologies such as EDR, SIEM, and SOAR platforms, to minimise the impact and prevent further infiltration by the threat actor.",
      "7-tier": "Advanced",
      "7-points": "7",
      "7-conversation" : "",
      "7-recommendation" : "Deploy specialised security solutions to detect and respond to sophisticated and stealthy cyber attacks. Utilise advanced threat detection technologies, such as behavioural analytics, machine learning, and threat intelligence, to identify indicators of compromise and abnormal behaviour indicative of APT activity. Implement automated response actions to contain and remediate APTs promptly. Configure centralised monitoring and reporting to track APT incidents and analyse attack patterns.",
      "8": "Purple Teaming",
      "8-summary": "Purple teaming is a collaborative security testing approach that brings together the red team (attackers) and blue team (defenders) to simulate realistic cyber attack scenarios and evaluate an organization's security posture. Unlike traditional red team engagements, which focus solely on simulating attacks, purple teaming involves close coordination between the red and blue teams throughout the testing process. This enables organizations to identify weaknesses in their security controls, improve detection and response capabilities, and enhance overall resilience against cyber threats by fostering communication, knowledge sharing, and continuous improvement between offensive and defensive security teams.",
      "8-tier": "Advanced",
      "8-points": "8",
      "8-conversation" : "",
      "8-recommendation" : "Collaborate between the Red Team (attackers) and Blue Team (defenders) to simulate real-world cyber attacks and assess an organisation's security posture effectively. Utilise Purple Teaming exercises to identify and exploit vulnerabilities in defensive controls, assess incident response capabilities, and improve overall security resilience. Conduct regular debrief sessions to share insights and lessons learned between the Red and Blue Teams, enhancing knowledge and skillsets across the security team."
        }
    } 
